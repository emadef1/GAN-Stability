{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTexi1uIO8ks"
      },
      "source": [
        "# preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU3ChX6DMh5d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "# from utils.const import *\n",
        "# from utils.helperFunctions import *\n",
        "# from utils.models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uHnLGRUgLDj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Path of the model (saved/to save)\n",
        "modelFolder = './models/'\n",
        "\n",
        "# When True, retrain the whole model\n",
        "retrain = True\n",
        "\n",
        "# Downsample the dataset\n",
        "ds = True\n",
        "\n",
        "# Specify number of seconds for the window. Default: 16\n",
        "window_size = 16\n",
        "\n",
        "# Model hyper-parameters\n",
        "batch_size = 4\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Seed for reproducibility\n",
        "seed = 151836\n",
        "\n",
        "# Classes to drop in the dataset\n",
        "classes_to_drop=[\n",
        "    'stabf','stab']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjXMMgcXgo4G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "def setSeed(seed=seed):\n",
        "    \"\"\"\n",
        "    Setting the seed for reproducibility\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "setSeed()\n",
        "\n",
        "def min_max_norm(self,col):\n",
        "    self._data[col]=(self._data[col]-self._data[col].min())/(self._data[col].max()-self._data[col].min())\n",
        "\n",
        "\n",
        "def std_scaler(self,col):\n",
        "    self._data[col]=(self._data[col]-self._data[col].mean())/(self._data[col].std())\n",
        "\n",
        "\n",
        "def f1(test_loader, model):\n",
        "    f1 = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, labels) in enumerate(test_loader):\n",
        "            outputs = model(data)\n",
        "            pred = outputs.data.max(1, keepdim=True)[1]\n",
        "            f1 += f1_score(labels, pred, average='macro')\n",
        "    avg_f1 = f1/len(test_loader)\n",
        "    return (avg_f1)\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_path='/content/new_dataset.csv', classes_to_drop=classes_to_drop, window_size=window_size, normalize=True, normalize_method='mean_std', auth=False, target=None):\n",
        "\n",
        "        self._window_size=window_size\n",
        "        self._data=pd.read_csv(file_path)\n",
        "\n",
        "        # if auth==True:\n",
        "        #     if target != 'J':\n",
        "        #         self._data = self._data[self._data['stabf'].isin([target, 'J'])]\n",
        "        #     else:\n",
        "        #         self._data = self._data[self._data['stabf'].isin([target, 'I'])]\n",
        "\n",
        "        #     self._data['stabf'] = self._data['stabf'].apply(lambda x: target if x == target else 'Z')\n",
        "        #     self._data['stabf'] = self._data['stabf'].map({target: 1, 'Z': 0}).fillna(0).astype(int)\n",
        "\n",
        "\n",
        "        # # Random Undersampling\n",
        "        # X = self._data.drop('stabf', axis=1)\n",
        "        # y = self._data['stabf']\n",
        "\n",
        "        # # sampler = RandomUnderSampler(sampling_strategy='not minority', random_state=seed)\n",
        "        # # X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "\n",
        "        # # X_resampled['Class'] = y_resampled\n",
        "        # self._data = X\n",
        "\n",
        "        # The data is sorted by Class A,B,C the indexes of the dataframe have restarted by ignore index\n",
        "        self._data = self._data.sort_values(by=['stabf'], inplace=False,ignore_index = True)\n",
        "\n",
        "        # class_uniq contains the letters of the drivers A,B and it loops across all of them\n",
        "        for class_uniq in list(self._data['stabf'].unique()):\n",
        "            # Find the total number of elements belonging to a class\n",
        "            tot_number=sum(self._data['stabf']==class_uniq)\n",
        "            # Number of elements to drop so that the class element is divisible by window size\n",
        "            to_drop=tot_number%window_size\n",
        "            # Returns the index of the first element of the class\n",
        "            index_to_start_removing=self._data[self._data['stabf']==class_uniq].index[0]\n",
        "            # Drop element from first element to the element required\n",
        "            self._data.drop(self._data.index[index_to_start_removing:index_to_start_removing+to_drop],inplace=True)\n",
        "\n",
        "\n",
        "        # Resetting index of dataframe after dropping values\n",
        "        self._data = self._data.reset_index()\n",
        "        self._data = self._data.drop(['index'], axis=1)\n",
        "\n",
        "        index_starting_class=[] # This array contains the starting index of each class in the df\n",
        "        for class_uniq in list(self._data['stabf'].unique()):\n",
        "            # Appending the index of first element of each clas\n",
        "            index_starting_class.append(self._data[self._data['stabf']==class_uniq].index[0])\n",
        "\n",
        "        # Create the sequence of indexs of the windows\n",
        "        sequences=[]\n",
        "        for i in range(len(index_starting_class)):\n",
        "            # Check if beginning of next class is there\n",
        "            if i!=len(index_starting_class)-1:\n",
        "                ranges=np.arange(index_starting_class[i], index_starting_class[i+1])\n",
        "            else:\n",
        "                ranges = np.arange(index_starting_class[i], len(self._data))\n",
        "            for j in range(0,len(ranges),int(self._window_size/2)):\n",
        "                if len(ranges[j:j+self._window_size])==16:\n",
        "                    sequences.append(ranges[j:j+self._window_size])\n",
        "        self._sequences=sequences\n",
        "\n",
        "\n",
        "        # Take only the 'Class' which are the actual labels and store it in the labels of self\n",
        "        self._labels=self._data['stabf']\n",
        "        # Dropping columns which have constant measurements because they would return nan in std\n",
        "        self._data.drop(classes_to_drop, inplace=True, axis=1)\n",
        "\n",
        "        # Function to normalize the data either with min_max or mean_std\n",
        "        if normalize and not auth:\n",
        "            for col in self._data.columns:\n",
        "                if normalize_method=='min_max':\n",
        "                    min_max_norm(self,col)\n",
        "                elif normalize_method==\"mean_std\":\n",
        "                    std_scaler(self,col)\n",
        "\n",
        "        # Create the array holding the windowed multidimensional arrays\n",
        "        X=np.empty((len(sequences), self._window_size, len(self._data.columns)))\n",
        "        y=[]\n",
        "\n",
        "        for n_row, sequence in enumerate(sequences):\n",
        "            X[n_row,:,:]=self._data.iloc[sequence]\n",
        "            # The corresponding driver of the sequence is the driver at first sequence\n",
        "            y.append(self._labels[sequence[0]])\n",
        "\n",
        "        assert len(y)==len(X)\n",
        "        # Assign the windowed dataset to the X of self\n",
        "        self._X= X\n",
        "\n",
        "        # Targets is a transformed version of y with drivers are encoded into 0 to 9\n",
        "        # targets = preprocessing.LabelEncoder().fit_transform(y)\n",
        "        # class_labels = encoder.classes_\n",
        "        # for code, label in enumerate(class_labels):\n",
        "        #   print(f'Code: {code} -> Label: {label}')\n",
        "        # targets = torch.as_tensor(targets)  # Just converting it to a pytorch tensor\n",
        "        self._y=y # Assign it to y of self\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._X)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.FloatTensor(self._X[index,:,:]), self._y[index]\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        inputs = inputs\n",
        "        labels = labels\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # Collect predictions and true labels\n",
        "        y_true += labels.data.cpu().numpy().tolist()\n",
        "        y_pred += preds.cpu().numpy().tolist()\n",
        "\n",
        "    # Calculate accuracy and loss\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "    epoch_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1\n",
        "\n",
        "\n",
        "def evaluateBinary(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            # loss = criterion(outputs, labels)\n",
        "            loss = criterion(outputs.squeeze(), labels.float())\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        # preds = (outputs > 0.5).float()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # Collect predictions and true labels\n",
        "        y_true += labels.data.cpu().numpy().tolist()\n",
        "        y_pred += preds.cpu().numpy().tolist()\n",
        "\n",
        "    # Calculate accuracy and loss\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "    epoch_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv-QwhKMv4Wy"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features,):\n",
        "        super(Generator, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_features = num_features\n",
        "        self.window_size = window_size\n",
        "        self.layer1 = nn.Linear(num_features, 128)\n",
        "        self.layer2 = nn.Linear(128, 256)\n",
        "        self.layer3 = nn.Linear(256, 512)\n",
        "        self.layer4 = nn.Linear(512, batch_size*window_size)\n",
        "        self.layer5 = nn.Linear(batch_size*window_size, num_features)\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.layer1(x))\n",
        "        x = self.leaky_relu(self.layer2(x))\n",
        "        x = self.leaky_relu(self.layer3(x))\n",
        "        x = self.leaky_relu(self.layer4(x))\n",
        "        x = self.layer5(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCTrkBiQnHgG"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/smart_grid_stability_augmented.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VgTgy1u6Bmc9"
      },
      "outputs": [],
      "source": [
        "# @title stabf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df.groupby('stabf').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rw0YcgjAPj9_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df['stabf'] = encoder.fit_transform(df['stabf'])\n",
        "\n",
        "# Retrieve the mapping of numerical codes to original class labels\n",
        "class_labels = encoder.classes_\n",
        "\n",
        "# Display the mapping\n",
        "for code, label in enumerate(class_labels):\n",
        "    print(f'Code: {code} -> Label: {label}')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_8niT9pAhrr"
      },
      "outputs": [],
      "source": [
        "#  Create a new DataFrame containing only rows with value 0\n",
        "new_df = df[df['stabf'] == 0]\n",
        "\n",
        "# Display the new DataFrame\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GBuKEhGAjIm"
      },
      "outputs": [],
      "source": [
        "new_df.to_csv('new_dataset.csv', index=False)\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o723dQMYnDGf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUDeWckM9pOy"
      },
      "outputs": [],
      "source": [
        "trainSize = 0.9\n",
        "# valSize = 0.05\n",
        "a = CustomDataset()\n",
        "\n",
        "# Defining sizes\n",
        "train_size = int(trainSize * len(a))\n",
        "test_size = len(a)-train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    a, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=4,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCakxEj14FZL"
      },
      "outputs": [],
      "source": [
        "for i, (inputs,Labels) in enumerate(train_loader):\n",
        "  Labels = Labels.to(device)\n",
        "  print(Labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdFPblBgwvWj"
      },
      "outputs": [],
      "source": [
        "!pip install torchattacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3uojh3PPEkT"
      },
      "source": [
        "# GAN-based stability prediction augemnted with novel adverserial training layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4H4DKQdeyi7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3E01uSw15J0"
      },
      "outputs": [],
      "source": [
        "import torchattacks\n",
        "# Define the generator and discriminator for the GAN\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, batch_size,window_size,num_features,latent_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_features = num_features\n",
        "        self.window_size = window_size\n",
        "       # self.fc1 = nn.Linear(latent_dim, 128)\n",
        "        self.fc1 = nn.Linear(num_features, latent_dim)\n",
        "        self.fc2 = nn.Linear(latent_dim, 128)\n",
        "        self.fc3 = nn.Linear(128,batch_size*window_size)\n",
        "        self.fc4 = nn.Linear(batch_size*window_size,num_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        #return x.view(x.size(0), 1, -1)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_features, 160)\n",
        "        self.fc2 = nn.Linear(160, 200)\n",
        "        self.fc3 = nn.Linear(200, 256)\n",
        "        self.fc4 = nn.Linear(256, 512)\n",
        "        self.fc5 = nn.Linear(512, 1)\n",
        "        self.window_size = window_size\n",
        "        self.num_features = num_features\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def forward(self, x):\n",
        "      #x = x.view(-1, self.num_features)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = F.relu(self.fc3(x))\n",
        "      x = F.relu(self.fc4(x))\n",
        "      x = torch.sigmoid(self.fc5(x))\n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "# Define the GAN training function\n",
        "\n",
        "def train_gan(generator, discriminator, train_loader, num_epochs=100, lr=0.0002,\n",
        "              device=torch.device('cpu')):\n",
        "\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    # Define the loss functions and optimizers\n",
        "\n",
        "    adversarial_loss = nn.BCELoss()\n",
        "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (inputs,Labels) in enumerate(train_loader):\n",
        "            # Move data to device\n",
        "            inputs = inputs.to(device)\n",
        "            Labels = Labels.to(device)\n",
        "\n",
        "            # Train discriminator on real data\n",
        "            discriminator_optimizer.zero_grad()\n",
        "            # real_labels = torch.ones(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            real_labels = torch.zeros(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            real_outputs = discriminator(inputs)\n",
        "            discriminator_loss_real = adversarial_loss(real_outputs, real_labels)\n",
        "            discriminator_loss_real.backward()\n",
        "\n",
        "            # Train discriminator on fake data generated by the generator\n",
        "            generator_optimizer.zero_grad()\n",
        "            latent_inputs = torch.randn(inputs.shape[0], inputs.shape[1], inputs.shape[2]).to(device)\n",
        "            fake_inputs = generator(latent_inputs)\n",
        "            # fake_labels = torch.zeros(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            fake_labels = torch.ones(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            fake_outputs = discriminator(fake_inputs)\n",
        "            discriminator_loss_fake = adversarial_loss(fake_outputs, fake_labels)\n",
        "            discriminator_loss_fake.backward()\n",
        "            discriminator_optimizer.step()\n",
        "\n",
        "\n",
        "            attack_fgsm = torchattacks.FGSM(discriminator, eps=0.05)\n",
        "            adversarial_inputs_fgsm = attack_fgsm(inputs, torch.zeros_like(real_labels))\n",
        "            adversarial_outputs_fgsm = discriminator(adversarial_inputs_fgsm.detach())\n",
        "            adversarial_labels_fgsm = torch.ones(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            discriminator_loss_fgsm = adversarial_loss(adversarial_outputs_fgsm, adversarial_labels_fgsm)\n",
        "            discriminator_loss_fgsm.backward()\n",
        "            discriminator_optimizer.step()\n",
        "\n",
        "            # attack_fgsm = torchattacks.FGSM(discriminator, eps=0.05)\n",
        "            # adversarial_inputs_fgsm = attack_fgsm(inputs, torch.ones_like(real_labels))\n",
        "            # attack_bim = torchattacks.BIM(discriminator, eps=0.05)\n",
        "            # adversarial_inputs_bim = attack_bim(inputs, torch.ones_like(real_labels))\n",
        "            # adversarial_inputs_combined = torch.cat([adversarial_inputs_fgsm, adversarial_inputs_bim], dim=0)\n",
        "            # fake_labels = torch.zeros(adversarial_inputs_combined.size(0), adversarial_inputs_combined.size(1), 1).to(device)\n",
        "            # fake_outputs = discriminator(adversarial_inputs_combined)\n",
        "            # discriminator_loss_fake = adversarial_loss(fake_outputs, fake_labels)\n",
        "            # discriminator_loss_fake.backward()\n",
        "            # discriminator_optimizer.step()\n",
        "\n",
        "            # Train generator to generate samples that increase the discriminator loss\n",
        "            generator_optimizer.zero_grad()\n",
        "            latent_inputs = torch.randn(inputs.shape[0], inputs.shape[1], inputs.shape[2]).to(device)\n",
        "            fake_inputs = generator(latent_inputs)\n",
        "            # @S: generator wants to maximize the probability of the discriminator being wrong. So loss is computed between discriminator's output to a fake image and the\n",
        "            #fake label (if the fake label is 0)\n",
        "            # fake_labels = torch.zeros(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            fake_labels = torch.ones(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            generator_loss =adversarial_loss(discriminator(fake_inputs), real_labels)\n",
        "            generator_loss.backward()\n",
        "            generator_optimizer.step()\n",
        "            if i % 10 == 0:\n",
        "              print('Epoch [{}/{}], Step [{}/{}], Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'\n",
        "                      .format(epoch, num_epochs, i, len(train_loader),\n",
        "discriminator_loss_real.item() + discriminator_loss_fake.item(), generator_loss.item()))\n",
        "                # Return the trained generator\n",
        "    return generator,discriminator\n",
        "\n",
        "\n",
        "# Define the number of epochs and learning rate for training the GAN\n",
        "num_epochs = 250\n",
        "lr = 0.0002\n",
        "inputs, classes = next(iter(train_loader))\n",
        "# Create the GAN models\n",
        "batch_size, window_size, num_features = inputs.shape\n",
        "generator = Generator(batch_size,window_size,num_features)\n",
        "discriminator = Discriminator(batch_size, window_size, num_features)\n",
        "\n",
        "# Train the GAN on your data\n",
        "trained_generator_new,trained_discriminator = train_gan(generator, discriminator, train_loader, num_epochs=num_epochs, lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQcucqDEI3GA"
      },
      "outputs": [],
      "source": [
        "# Load the saved state dictionaries\n",
        "trained_generator_new.load_state_dict(torch.load('/content/trained_generator_Grid_FGSM (4).pth'))\n",
        "trained_discriminator.load_state_dict(torch.load('/content/trained_discriminator_Grid_FGSM (4).pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IljmbW6ePOnj"
      },
      "source": [
        "# Evaluation of stable class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY374_7POTEb"
      },
      "outputs": [],
      "source": [
        "# List to store predicted class labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "trained_discriminator.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in test_loader:\n",
        "\n",
        "        # Get the discriminator's output for the current batch\n",
        "        inputs = inputs.to(device)\n",
        "        surrogate_outputs = trained_discriminator(inputs)\n",
        "\n",
        "        # Apply thresholding to determine class labels\n",
        "        threshold = 0.5\n",
        "        batch_predicted_labels = (surrogate_outputs >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "        predicted_labels.append(batch_predicted_labels)\n",
        "\n",
        "# Convert the list of predicted labels to a single tensor\n",
        "predicted_labels = torch.cat(predicted_labels, dim=0)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLk1E4avOXa1"
      },
      "outputs": [],
      "source": [
        "# True labels (all 1)\n",
        "true_labels = torch.zeros_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvPa9M_5PZ6C"
      },
      "source": [
        "# Evaluation of unstable class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccb8zbEfe0TB"
      },
      "outputs": [],
      "source": [
        "#  Create a new DataFrame containing only rows with value 0 in 'column_name'\n",
        "new_df = df[df['stabf'] == 1]\n",
        "\n",
        "# Display the new DataFrame\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf2fXCLZe5T4"
      },
      "outputs": [],
      "source": [
        "new_df.to_csv('new_dataset.csv', index=False)\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5Y7DGqbe_x-"
      },
      "outputs": [],
      "source": [
        "trainSize = 0.01\n",
        "# valSize = 0.05\n",
        "a = CustomDataset()\n",
        "\n",
        "# Defining sizes\n",
        "train_size = int(trainSize * len(a))\n",
        "test_size = len(a)-train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    a, [train_size, test_size])\n",
        "\n",
        "train_loader1 = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=4,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "test_loader1 = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhQwC4eHEFI"
      },
      "outputs": [],
      "source": [
        "for i, (inputs,Labels) in enumerate(test_loader1):\n",
        "  Labels = Labels.to(device)\n",
        "  print(Labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDTT-A3OfF0V"
      },
      "outputs": [],
      "source": [
        "# List to store predicted class labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "trained_discriminator.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in test_loader1:\n",
        "\n",
        "        # Get the discriminator's output for the current batch\n",
        "        inputs = inputs.to(device)\n",
        "        surrogate_outputs = trained_discriminator(inputs)\n",
        "\n",
        "        # Apply thresholding to determine class labels\n",
        "        threshold = 0.5\n",
        "        batch_predicted_labels = (surrogate_outputs >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "        predicted_labels.append(batch_predicted_labels)\n",
        "\n",
        "# Convert the list of predicted labels to a single tensor\n",
        "predicted_labels = torch.cat(predicted_labels, dim=0)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l84VhMVDfRaZ"
      },
      "outputs": [],
      "source": [
        "# True labels (all 1)\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E7vVNfEPgda"
      },
      "source": [
        "# Evaluation of Both classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO2RI49qw6Zy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# List to store predicted class labels and true labels\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "trained_discriminator.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Loop through the first test loader\n",
        "    for inputs, labels in test_loader1:\n",
        "        inputs = inputs.to(device)\n",
        "        surrogate_outputs = trained_discriminator(inputs)\n",
        "        threshold = 0.5\n",
        "        batch_predicted_labels = (surrogate_outputs >= threshold).int()\n",
        "        predicted_labels.append(batch_predicted_labels.cpu().numpy())\n",
        "        true_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    # Loop through the second test loader\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        surrogate_outputs = trained_discriminator(inputs)\n",
        "        threshold = 0.5\n",
        "        batch_predicted_labels = (surrogate_outputs >= threshold).int()\n",
        "        predicted_labels.append(batch_predicted_labels.cpu().numpy())\n",
        "        true_labels.append(labels.cpu().numpy())\n",
        "\n",
        "# Convert the list of predicted labels and true labels to numpy arrays\n",
        "predicted_labels = np.concatenate(predicted_labels)\n",
        "predicted_labels_selected = predicted_labels[:, 0, 0]\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels_selected)\n",
        "f1 = f1_score(true_labels, predicted_labels_selected)\n",
        "\n",
        "# Print accuracy and F1 score\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lVhk39ZPlSx"
      },
      "source": [
        "# Evalution of the Adverserial attacks(whitebox) being classfied as unstable\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tF9PPyu6bN9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the pre-trained model\n",
        "trained_discriminator.eval()\n",
        "predicted_labels_fgsm= []\n",
        "predicted_labels_bim= []\n",
        "predicted_labels_cw= []\n",
        "predicted_labels_RFGSM=[]\n",
        "predicted_labels_PGD=[]\n",
        "predicted_labels_square=[]\n",
        "\n",
        "# Attack parameters\n",
        "epsilon_fgsm = 0.05 # Perturbation magnitude for FGSM\n",
        "epsilon_bim = 0.05# Perturbation magnitude for BIM\n",
        "epsilon_cw = 0.05# Perturbation magnitude for C&W\n",
        "epsilon_square = 0.5\n",
        "\n",
        "threshold = 0.5\n",
        "correct_original = 0\n",
        "correct_adversarial_fgsm = 0\n",
        "correct_adversarial_bim = 0\n",
        "correct_adversarial_cw = 0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader:\n",
        "    # Forward pass on the original input\n",
        "    outputs_original = trained_discriminator(inputs)\n",
        "    _, predicted_original = torch.max(outputs_original, 1)\n",
        "\n",
        "    # FGSM: Craft adversarial example\n",
        "    attack_fgsm = torchattacks.FGSM(trained_discriminator, eps=epsilon_fgsm)\n",
        "    adversarial_inputs_fgsm = attack_fgsm(inputs, Labels.unsqueeze(1))\n",
        "\n",
        "    # BIM: Craft adversarial example\n",
        "    attack_bim = torchattacks.BIM(trained_discriminator, eps=epsilon_bim)\n",
        "    adversarial_inputs_bim = attack_bim(inputs, Labels.unsqueeze(1))\n",
        "\n",
        "\n",
        "    attack_RFGSM = torchattacks.RFGSM(trained_discriminator, eps=epsilon_bim)\n",
        "    adversarial_inputs_RFGSM = attack_RFGSM(inputs, Labels.unsqueeze(1))\n",
        "\n",
        "    attack_PGD = torchattacks.PGD(trained_discriminator, eps=epsilon_bim)\n",
        "    adversarial_inputs_PGD = attack_PGD(inputs, Labels.unsqueeze(1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Forward pass on the adversarial inputs\n",
        "    outputs_adversarial_fgsm = trained_discriminator(adversarial_inputs_fgsm)\n",
        "    batch_predicted_labels1 = (outputs_adversarial_fgsm >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "    predicted_labels_fgsm.append(batch_predicted_labels1)\n",
        "    outputs_adversarial_bim = trained_discriminator(adversarial_inputs_bim)\n",
        "    batch_predicted_labels2 = (outputs_adversarial_bim >= threshold).int()\n",
        "    predicted_labels_bim.append(batch_predicted_labels2)\n",
        "    outputs_adversarial_RFGSM = trained_discriminator(adversarial_inputs_RFGSM)\n",
        "    batch_predicted_labels4 = (outputs_adversarial_RFGSM >= threshold).int()\n",
        "    predicted_labels_RFGSM.append(batch_predicted_labels4)\n",
        "    outputs_adversarial_PGD = trained_discriminator(adversarial_inputs_PGD)\n",
        "    batch_predicted_labels5 = (outputs_adversarial_PGD >= threshold).int()\n",
        "    predicted_labels_PGD.append(batch_predicted_labels5)\n",
        "\n",
        "\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels_fgsm, dim=0)\n",
        "predicted_labels1 = torch.cat(predicted_labels_bim, dim=0)\n",
        "predicted_labels3= torch.cat(predicted_labels_RFGSM, dim=0)\n",
        "predicted_labels4= torch.cat(predicted_labels_PGD, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFxvd-FoLtp0"
      },
      "outputs": [],
      "source": [
        "\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oosjv6vOLu-v"
      },
      "outputs": [],
      "source": [
        "\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels1 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re28pFtpLwUd"
      },
      "outputs": [],
      "source": [
        "\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels3 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE5KmvnCLxr1"
      },
      "outputs": [],
      "source": [
        "\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels4 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybl25MVs4J8Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the pre-trained model\n",
        "trained_discriminator.eval()\n",
        "predicted_labels_fgsm= []\n",
        "predicted_labels_bim= []\n",
        "predicted_labels_cw= []\n",
        "predicted_labels_RFGSM=[]\n",
        "predicted_labels_PGD=[]\n",
        "predicted_labels_square=[]\n",
        "\n",
        "# Attack parameters\n",
        "epsilon_fgsm = 0.05 # Perturbation magnitude for FGSM\n",
        "epsilon_bim = 0.05# Perturbation magnitude for BIM\n",
        "epsilon_cw = 0.05# Perturbation magnitude for C&W\n",
        "epsilon_square = 0.5\n",
        "\n",
        "threshold = 0.5\n",
        "correct_original = 0\n",
        "correct_adversarial_fgsm = 0\n",
        "correct_adversarial_bim = 0\n",
        "correct_adversarial_cw = 0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader1:\n",
        "    # Forward pass on the original input\n",
        "    outputs_original = trained_discriminator(inputs)\n",
        "    _, predicted_original = torch.max(outputs_original, 1)\n",
        "\n",
        "    # FGSM: Craft adversarial example\n",
        "    attack_fgsm = torchattacks.FGSM(trained_discriminator, eps=epsilon_fgsm)\n",
        "    adversarial_inputs_fgsm = attack_fgsm(inputs, Labels.unsqueeze(1))\n",
        "\n",
        "    # BIM: Craft adversarial example\n",
        "    attack_bim = torchattacks.BIM(trained_discriminator, eps=epsilon_bim)\n",
        "    adversarial_inputs_bim = attack_bim(inputs, Labels.unsqueeze(1))\n",
        "\n",
        "\n",
        "\n",
        "    attack_RFGSM = torchattacks.RFGSM(trained_discriminator, eps=epsilon_bim)\n",
        "    adversarial_inputs_RFGSM = attack_RFGSM(inputs, Labels.unsqueeze(1))\n",
        "\n",
        "    attack_PGD = torchattacks.PGD(trained_discriminator, eps=epsilon_bim)\n",
        "    adversarial_inputs_PGD = attack_PGD(inputs, Labels.unsqueeze(1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Forward pass on the adversarial inputs\n",
        "    outputs_adversarial_fgsm = trained_discriminator(adversarial_inputs_fgsm)\n",
        "    batch_predicted_labels1 = (outputs_adversarial_fgsm >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "    predicted_labels_fgsm.append(batch_predicted_labels1)\n",
        "    outputs_adversarial_bim = trained_discriminator(adversarial_inputs_bim)\n",
        "    batch_predicted_labels2 = (outputs_adversarial_bim >= threshold).int()\n",
        "    predicted_labels_bim.append(batch_predicted_labels2)\n",
        "    outputs_adversarial_RFGSM = trained_discriminator(adversarial_inputs_RFGSM)\n",
        "    batch_predicted_labels4 = (outputs_adversarial_RFGSM >= threshold).int()\n",
        "    predicted_labels_RFGSM.append(batch_predicted_labels4)\n",
        "    outputs_adversarial_PGD = trained_discriminator(adversarial_inputs_PGD)\n",
        "    batch_predicted_labels5 = (outputs_adversarial_PGD >= threshold).int()\n",
        "    predicted_labels_PGD.append(batch_predicted_labels5)\n",
        "\n",
        "\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels_fgsm, dim=0)\n",
        "predicted_labels1 = torch.cat(predicted_labels_bim, dim=0)\n",
        "predicted_labels3= torch.cat(predicted_labels_RFGSM, dim=0)\n",
        "predicted_labels4= torch.cat(predicted_labels_PGD, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21J7oymq6_oR"
      },
      "outputs": [],
      "source": [
        "\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WSeviNh8rNd"
      },
      "outputs": [],
      "source": [
        "\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels1 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKOAXtRoBXpF"
      },
      "outputs": [],
      "source": [
        "\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels3 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTsKLhnSBc1N"
      },
      "outputs": [],
      "source": [
        "\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels4 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk9xnaNVPwAs"
      },
      "source": [
        "# Training the surrogate model for Greybox attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNcSJ33YNVg2"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/smart_grid_stability_augmented.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHmCHiNSNZ91"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df['stabf'] = encoder.fit_transform(df['stabf'])\n",
        "\n",
        "# Retrieve the mapping of numerical codes to original class labels\n",
        "class_labels = encoder.classes_\n",
        "\n",
        "# Display the mapping\n",
        "for code, label in enumerate(class_labels):\n",
        "    print(f'Code: {code} -> Label: {label}')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-1TAcAZNeCu"
      },
      "outputs": [],
      "source": [
        "df.to_csv('new_dataset.csv', index=False)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbU2QoBtxnGP"
      },
      "outputs": [],
      "source": [
        "a = CustomDataset()\n",
        "# Size of the split\n",
        "trainSize = 0.75\n",
        "valSize = 0.05\n",
        "testSize = 0.20\n",
        "\n",
        "# Defining sizes\n",
        "train_size = int(trainSize * len(a))\n",
        "val_size = int(valSize * len(a))\n",
        "test_size = len(a)-train_size-val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    a, [train_size, val_size, test_size])\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False,\n",
        "                                           drop_last=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=False,\n",
        "                                                drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJpVgWGOJeaG"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class RNNBinaryClassification(torch.nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features, dropout_rate=0.5):\n",
        "        super(RNNBinaryClassification, self).__init__()\n",
        "        self.rnn1 = torch.nn.LSTM(num_features, 220, batch_first=True, bidirectional=True)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
        "        self.fc = torch.nn.Linear(440, 1)  # Output size is 1 for binary classification\n",
        "        self.sigmoid = torch.nn.Sigmoid()  # Sigmoid activation for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn1_out, _ = self.rnn1(x)\n",
        "        rnn1_out = self.dropout(rnn1_out[:, -1, :])\n",
        "        fc_out = self.fc(rnn1_out)\n",
        "        out = self.sigmoid(fc_out)\n",
        "        return out\n",
        "# Initialize your model, criterion, and optimizer\n",
        "model = RNNBinaryClassification(batch_size, window_size, 12).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "retrain = False\n",
        "\n",
        "if not os.path.exists('./models/rnn_auth.pt') or retrain:\n",
        "    # Training loop\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), labels.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        average_loss = total_loss / len(train_loader)\n",
        "\n",
        "        print(f'[💪 EPOCH {epoch+1}/{10}] Loss: {average_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6LUv4Fp0eWd"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    predictions = (outputs > 0.5).float()\n",
        "\n",
        "    for p, l in zip(predictions, labels.float()):\n",
        "        if p == l:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    total_samples += labels.size(0)\n",
        "\n",
        "    y_true.extend(labels.cpu().numpy())\n",
        "    y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "acc = correct_predictions/total_samples\n",
        "f1 = f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "print('[👑 TEST GRU AUTH]\\n')\n",
        "print(f'[🎯 ACCURACY] {acc:.3f}')\n",
        "print(f'[⚖️ F1 SCORE] {f1:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dy1iW1KQBS9"
      },
      "source": [
        "# Attacking the surrogate model and testing adverserial exampels (greybox) against GAN-baes stability prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNWbJJ1zpDPk"
      },
      "outputs": [],
      "source": [
        "pip install adversarial-robustness-toolbox\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D50eyzu3ZNog"
      },
      "outputs": [],
      "source": [
        "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescentPyTorch, ProjectedGradientDescentNumpy, CarliniLInfMethod, CarliniWagnerASR,UniversalPerturbation\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.attacks.evasion.iterative_method import BasicIterativeMethod\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "    model=model,\n",
        "    loss=criterion,\n",
        "    input_shape=(12,),\n",
        "    nb_classes=2,\n",
        "    device_type=\"cpu\"\n",
        "    # device_type=\"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Define FGSM, BIM, and CW attacks\n",
        "fgsm_attack = FastGradientMethod(estimator=classifier, eps=0.05)\n",
        "bim_attack = BasicIterativeMethod(estimator=classifier, eps=0.05)\n",
        "pgd_attack = ProjectedGradientDescentNumpy(estimator=classifier, eps=0.05)\n",
        "\n",
        "\n",
        "def evaluate_clean_data(model, test_loader):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predictions = (outputs > 0.5).float()\n",
        "\n",
        "            correct_predictions += (predictions == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predictions.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(y_true,y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "    print('[👑 EVALUATION ON CLEAN DATA]\\n')\n",
        "    print(f'[🎯 ACCURACY] {acc:.3f}')\n",
        "    print(f'[⚖️ F1 SCORE] {f1:.3f}')\n",
        "\n",
        "\n",
        "evaluate_clean_data(model, test_loader)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4nVwwAh5iU6"
      },
      "outputs": [],
      "source": [
        "def evaluate_attack(model, test_loader, attack):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    correct_predictions1 = 0\n",
        "    predicted_labels = []\n",
        "    true_labels=[]\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to device\n",
        "        adv_inputs = attack.generate(x=inputs.cpu().numpy())\n",
        "        adv_inputs = torch.tensor(adv_inputs).to(device)\n",
        "        outputs = trained_discriminator(adv_inputs)\n",
        "        predictions = (outputs >= 0.5).int()\n",
        "        predicted_labels.append(predictions.numpy())\n",
        "        true_labels.append(labels.numpy())\n",
        "\n",
        "\n",
        "    # Concatenate the list of predicted labels to a single tensor\n",
        "    predicted_labels = np.concatenate(predicted_labels)\n",
        "    predicted_labels_selected = predicted_labels[:, 0, 0]\n",
        "    true_labels = np.concatenate(true_labels, axis=0)\n",
        "    true_labels = np.ones_like(true_labels)\n",
        "\n",
        "    acc = accuracy_score(true_labels, predicted_labels_selected)\n",
        "    f1 = f1_score(true_labels, predicted_labels_selected)\n",
        "\n",
        "    print('[👑 EVALUATION UNDER ATTACK]\\n')\n",
        "    print(f'[🎯 ACCURACY] {acc:.3f}')\n",
        "    print(f'[🎯 F1] {f1:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaRuqQS_o_GM"
      },
      "outputs": [],
      "source": [
        "# Evaluate under FGSM attack\n",
        "evaluate_attack(model, test_loader, fgsm_attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6OL8bdlo5YT"
      },
      "outputs": [],
      "source": [
        "# Evaluate under BIM attack\n",
        "evaluate_attack(model, test_loader, bim_attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUliZSepO2Of"
      },
      "outputs": [],
      "source": [
        "# Evaluate under BIM attack\n",
        "evaluate_attack(model, test_loader, pgd_attack)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
